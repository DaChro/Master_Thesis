---
author: "Sebastian Holtkamp"
date: "05.02.2020"
title: "Master_Thesis_Experimentation"
output: html_document
---
  
```{r setup, include = FALSE}
library(keras)
library(raster)


#' Create tiles as subsets of a given raster image
#' @warning If fixed is set to TRUE parts of the input might not be made into tiles. 
#'          The right and bottom parts of the input image will be left out if raster dimension is not an exact multiple of target size.
#'
#' @source Partially based on the work of Christian Knoth at https://github.com/DaChro/cannons_at_marmots
#'
#' @param inputraster Raster file that will be subset. Format needs to be supported by raster library
#' @param targetsize 2D vector of desired tile size. Example: c(128, 128)
#' @param fixed Boolean value. Standard is TRUE. If TRUE only tiles fitting the desired tile size will be generated
#' @param targetdir Directory into which the results will be exported
#' @param targetformat String representing desired file format for output. Format needs to be supported by raster library
#'
#' @examples \dontrun{createSubsets("C:/User/Desktop/Raster.tif", c(128, 128), TRUE, "C:/User/Desktop/Raster_Tiles/ ".tif")}
create_subsets <- function(inputraster, targetsize, fixed = TRUE, targetdir, targetformat = ".tif"){
  
  # read files located at the path of inputraster as a brick
  temp_rstr <- brick(inputraster)
  
  # read dimensions of read raster file
  targetsizeX <- targetsize[1]
  targetsizeY <- targetsize[2]
  
  # if the generation of tiles in a fixed dimension (fixed = TRUE) is not forced, tiles in a close approximation of the target size will be generated
  if (fixed == FALSE){  
    # determine next number of quadrates in x and y direction, by simple rounding
    nsx <- round(ncol(temp_rstr) / targetsizeX)
    nsy <- round(nrow(temp_rstr) / targetsizeY)
    
    # determine quadrate size using rounded number of cells 
    aggfactorX <- ncol(temp_rstr)/nsx
    aggfactorY <- nrow(temp_rstr)/nsy
    
    # aggregate calculated infromation
    agg <- aggregate(temp_rstr[[1]],c(aggfactorX, aggfactorY))
    agg[] <- 1:ncell(agg)
    agg_poly <- rasterToPolygons(agg)
    names(agg_poly) <- "polis"
  }
  
  # if the generation of tiles in a fixed dimension (fixed = TRUE) is forced, no rounding is necessary
  if (fixed == TRUE){
    # aggregate given infromation
    agg <- aggregate(temp_rstr[[1]],c(targetsizeX, targetsizeY))
    agg[] <- 1:ncell(agg)
    agg_poly <- rasterToPolygons(agg)
    names(agg_poly) <- "polis"
  }
  
  # setting up progress reports
  print("Writing subset:")
  progress_count <- 0
  
  # use aggregated information from previous step to generate and write subset tiles 
  for(i in 1:ncell(agg)) {
    e1  <- extent(agg_poly[agg_poly$polis==i,])
    subs <- crop(temp_rstr,e1)
    
    temp <- floor(i / (ncell(agg) / 100))
    
    if(temp %% 10 == 0 && temp > 0 && temp > progress_count){
      # print progress of execution
      print(paste0("Progress: ", temp, "%"))
      progress_count <- progress_count + 10
    }
    
    # if fixed size is desired, check whether both dimensions of the generated tile fit target size
    if (fixed == TRUE && (dim(subs)[1] != targetsize[1]) || (dim(subs)[2] != targetsize[2])){
      # case: fixed is forced but at least one dimension not equal to target
      # --> do not generate this tile
    }
    else{
      # case 1: fixed is forced and dimensions fit
      # case 2: fixed is not forced
      # --> generate this tile
      
      # determine amount of leading zeros for correct file name
      lead <- (nchar(length(agg[])) - nchar(i))
      zeros <- paste(replicate(lead, "0"), collapse = "")
      
      # write file 
      writeRaster(subs,
                  filename = paste0(targetdir,"img_", zeros, i, targetformat),
                  overwrite = TRUE)
    }
  }
  
  # rename files to fill gaps left by skipped tiles 
  if (fixed == TRUE){
    # save current working directory and switch to targetdir to circumvent writing errors
    current_dir <- getwd()
    setwd(targetdir)
    
    # get number of tiles generated previously 
    n_tiles <- length(list.files(".", pattern = "*.tif"))
    
    # build vector of old file names (with gaps)
    old_files <- list.files(".", pattern = "*.tif", full.names = TRUE)
    
    # initiate vector of new file names (no gaps)
    new_files <- vector(length = n_tiles)
    
    # fill vector with new file names
    for (i in 1:n_tiles){
      lead <- (nchar(n_tiles) - nchar(i))
      zeros <- paste(replicate(lead, "0"), collapse = "")
      new_files[i] <- paste0("img_", zeros, i, targetformat)
    }
    
    # rename files
    file.rename(from = old_files, to = new_files)
    
    # reset working directory
    setwd(current_dir)
  }
}


#' Read directories of input tiles into multidimensional arrays
#'
#' @param inputdir Path to the files which shall be read into array
#' @param dimensions 2D vector of input image size. Example: c(128, 128)
#' @param format String representing  file format of input. Format needs to be supported by raster library
#'
#' @return Input data in an 3D array
#'
#' @examples \dontrun{readInput("C:/User/Desktop/Raster_Tiles/", c(128, 128), 6, ".tif")}
read_input <- function(inputdir, dimensions, channels, format){
  
  # determine parameters of input data
  n_input <- length(list.files(inputdir, pattern = paste0(format)))
  
  # determine dimensions of inpout data
  input_size_x <- dimensions[1]
  input_size_y <- dimensions[2]
  
  # build array to hold data
  data <- array(dim = c(n_input, input_size_x, input_size_y, channels))

  # setting up progress reports
  percent_input <- (n_input / 100)
  print("Reading data:")
  progress_count <- 0
  
  # populate data array
  for (i in 1: n_input){
    # calculate part of file name according to naming conventions of createSubsets()
    lead <- (nchar(n_input) - nchar(i))
    zeros <- paste(replicate(lead, "0"), collapse = "")
    
    # read tile data into brick
    raster_file <- brick(paste0(inputdir, "img_", zeros, i, format))
    
    # loop over channels to paste tile data into complete data array
    for(j in 1:channels){
      channel_matrix <- raster::as.matrix(subset(raster_file, j))
    
      # paste matrix into data array
      data[i, , , j] <- channel_matrix[ , ]
    }
    
    # print progress of execution
    temp <- floor(i / percent_input)
    
    if(temp %% 10 == 0 && temp > 0 && temp > progress_count){
      print(paste0("Progress: ", temp, "%"))
      progress_count <- progress_count + 10
    }
  }
  
  return(data)
}


#' Prepare data for usage by reading tiles, masks and target data , applying a training/test split to it and making it accessable via a variable
#'
#' @param split Numeric value between 0 and 1. Represents train/test split percentage.
#' @param dimensions 2D vector of input image size. Example: c(128, 128).
#' @param channels Integer of channels in input image.
#'
#' @return Returns list of matrices, containing training and test tiles and masks.
#' @export
#'
#' @examples \dontrun{data <- prep_data(c(128, 128), 6, 0.8)}
prep_data <- function(dimensions = c(128, 128), channels = 6, split = 0.8){
  
  tile_data <- read_input("F:/Master_Thesis/data/tiles/", dimensions, channels, ".tif")
  mask_data <- read_input("F:/Master_Thesis/data/masks/", dimensions, 1, ".tif")
  target_data <- read_input("F:/Master_Thesis/data/targets/tiles/", dimensions, channels, ".tif")

  
  # determine point in input data to split between train and test data set
  split_point <- floor(dim(tile_data)[1] * split)
  
  
  # initialize arrays to contain subsets
  train_data <- array(dim = c(split_point, dimensions[1], dimensions[2], channels))
  train_mask <- array(dim = c(split_point, dimensions[1], dimensions[2], 1))
  
  test_data <- array(dim = c((dim(tile_data)[1] - split_point), dimensions[1], dimensions[2], channels))
  test_mask <- array(dim = c((dim(mask_data)[1] - split_point), dimensions[1], dimensions[2], 1))
  
  
  # make traceable sample selection by sampling ids and building a vector from them
  sample_ids <- sample(1:(dim(tile_data)[1]), split_point)
  
  
  # initiate indices
  train_index = 1
  test_index = 1
  
  # loop over whole data and split tiles and masks into train and test data sets according to sampled ids
  for(i in 1 : (dim(tile_data)[1])){
    
    if(i %in% sample_ids){
      # case: id is a sampled id --> point of data belongs into training set
      train_data[train_index, , , ] <- tile_data[i, , , ]
      train_mask[train_index, , , ] <- mask_data[i, , , 1]
      
      train_index <- train_index + 1
    }
    
    else {
      # case: id is not a sampled id --> point of data belongs to test set
      test_data[test_index, , , ] <- tile_data[i, , , ]
      test_mask[test_index, , , ] <- mask_data[i, , , 1]
      
      test_index <- test_index + 1
    }
    
  }
  

  # replace NAs in mask data with 0
  train_mask[is.na(train_mask)] <- 0
  test_mask[is.na(test_mask)] <- 0
  
  
  # make list of arrays to return
  prepped_data <- list("train_data" = train_data, "train_mask" = train_mask, "test_data" = test_data, "test_mask" = test_mask, "target_data" = target_data)
  
  
  return(prepped_data)
}   


#' Build a custom vgg16 and u-net hybrid Keras model
#'
#' @param input_shape Dimensions of input. Standard: 128*128 resolution, 1 channel greyscale; for RGB use 3 channels
#' @param num_classes Number of classes. Standard: 2 for binary classification. Example: Tree vs. not tree
#'
#' @return Returns a Keras model
#'
#' @examples \dontrun{model <- build_vgg_unet()}
build_custom_model <- function(input_shape = c(128, 128, 1), num_classes = 2) {
  
  
  #---Input-------------------------------------------------------------------------------------
  inputs <- layer_input(name = "input_1", shape = input_shape)
  
  
  #---Downsampling------------------------------------------------------------------------------
  down1 <- inputs %>%
    layer_conv_2d(name = "down1_conv1", filters = 64, kernel_size = 3, 
                  input_shape = c(128, 128, 1),
                  padding = "same", data_format = "channels_last", 
                  activation = "relu", kernel_initializer = "VarianceScaling") %>%
    layer_conv_2d(name = "down1_conv2", filters = 64, kernel_size = 3, 
                  padding = "same", data_format = "channels_last", 
                  activation = "relu", kernel_initializer = "VarianceScaling") 
  down1_pool <- down1 %>%
    layer_max_pooling_2d(name = "down1_pool", pool_size = c(2, 2), strides = c(2, 2)) 
  
  
  down2 <- down1_pool %>%
    layer_conv_2d(name = "down2_conv1", filters = 128, kernel_size = 3, 
                  padding = "same", data_format = "channels_last", 
                  activation = "relu", kernel_initializer = "VarianceScaling") %>%
    layer_conv_2d(name = "down2_conv2", filters = 128, kernel_size = 3, 
                  padding = "same", data_format = "channels_last", 
                  activation = "relu", kernel_initializer = "VarianceScaling") 
  down2_pool <- down2 %>%
    layer_max_pooling_2d(name = "down2_pool", pool_size = c(2, 2), strides = c(2, 2)) %>%
    layer_dropout(0.2)
  
  
  down3 <- down2_pool %>%
    layer_conv_2d(name = "down3_conv1", filters = 256, kernel_size = 3, 
                  padding = "same", data_format = "channels_last", 
                  activation = "relu", kernel_initializer = "VarianceScaling") %>%
    layer_conv_2d(name = "down3_conv2", filters = 256, kernel_size = 3,
                  padding = "same", data_format = "channels_last",
                  activation = "relu", kernel_initializer = "VarianceScaling") 
  down3_pool <- down3 %>%
    layer_max_pooling_2d(name = "down3_pool", pool_size = c(2, 2), strides = c(2, 2)) 
  
  
  down4 <- down3_pool %>%
    layer_conv_2d(name = "down4_conv1", filters = 512, kernel_size = 3, 
                  padding = "same", data_format = "channels_last", 
                  activation = "relu", kernel_initializer = "VarianceScaling") %>%
    layer_conv_2d(name = "down4_conv2", filters = 512, kernel_size = 3,
                  padding = "same", data_format = "channels_last",
                  activation = "relu", kernel_initializer = "VarianceScaling") 
  down4_pool <- down4 %>%
    layer_max_pooling_2d(name = "down4_pool", pool_size = c(2, 2), strides = c(2, 2)) 
 
  
   #---Center-----------------------------------------------------------------------------------
  center <- down4_pool %>%
    layer_dropout(0.2) 
  
  
  #---Upsampling--------------------------------------------------------------------------------
  up4 <- center %>%
    layer_conv_2d(name = "up4_conv1", filters = 512, kernel_size = 3, 
                  padding = "same", data_format = "channels_last", 
                  activation = "relu", kernel_initializer = "VarianceScaling") %>%
    layer_conv_2d(name = "up4_conv2", filters = 512, kernel_size = 3,
                  padding = "same", data_format = "channels_last",
                  activation = "relu", kernel_initializer = "VarianceScaling") %>%
    layer_batch_normalization() %>%
    layer_conv_2d_transpose(name = "up4_upconv_1", filters = 128, kernel_size = 2, strides = c(2, 2),
                            padding = "same", data_format = "channels_last", activation = "linear") %>%
    {layer_concatenate(name = "up4_conc1", inputs = list(down4, .))} 
  
  
  up3 <- up4 %>%
    layer_conv_2d(name = "up3_conv1", filters = 256, kernel_size = 3, 
                  padding = "same", data_format = "channels_last", 
                  activation = "relu", kernel_initializer = "VarianceScaling") %>%
    layer_conv_2d(name = "up3_conv2", filters = 256, kernel_size = 3,
                  padding = "same", data_format = "channels_last",
                  activation = "relu", kernel_initializer = "VarianceScaling") %>%
    layer_batch_normalization() %>%
    layer_conv_2d_transpose(name = "up3_upconv_1", filters = 128, kernel_size = 2, strides = c(2, 2),
                            padding = "same", data_format = "channels_last", activation = "linear") %>%
    {layer_concatenate(name = "up3_conc1", inputs = list(down3, .))} 
  
  
  up2 <- up3 %>%
    layer_conv_2d(name = "up2_conv1", filters = 128, kernel_size = 3, 
                  padding = "same", data_format = "channels_last", 
                  activation = "relu", kernel_initializer = "VarianceScaling") %>%
    layer_conv_2d(name = "up2_conv2", filters = 128, kernel_size = 3,
                  padding = "same", data_format = "channels_last",
                  activation = "relu", kernel_initializer = "VarianceScaling") %>%
    layer_batch_normalization() %>%
    layer_conv_2d_transpose(name = "up2_upconv1", filters = 128, kernel_size = 2, strides = c(2, 2),
                            padding = "same", data_format = "channels_last", activation = "linear") %>%
    {layer_concatenate(name = "up2_conc1", inputs = list(down2, .))} %>%
    layer_dropout(0.2)
  
  
  up1 <- up2 %>%
    layer_conv_2d(name = "up1_conv1", filters = 64, kernel_size = 3, 
                  padding = "same", data_format = "channels_last", 
                  activation = "relu", kernel_initializer = "VarianceScaling") %>%
    layer_conv_2d(name = "up1_conv2", filters = 64, kernel_size = 3,
                  padding = "same", data_format = "channels_last",
                  activation = "relu", kernel_initializer = "VarianceScaling") %>%
    layer_batch_normalization() %>%
    layer_conv_2d_transpose(name = "up1_upconv1", filters = 128, kernel_size = 2, strides = c(2, 2),
                            padding = "same", data_format = "channels_last", activation = "linear") %>%
    {layer_concatenate(name = "up1_conc1", inputs = list(down1, .))} 
  
  
  #---Classification/Output---------------------------------------------------------------------
  classify <- layer_conv_2d(up1, filters = num_classes, kernel_size = c(1, 1), activation = "sigmoid")
  
  
  # Build specified model and assign it to variable
  model <- keras_model(
    inputs = inputs,
    outputs = classify
  )
  
  # Compile model
  model %>% compile(
    loss = "binary_crossentropy",
    optimizer = optimizer_sgd(lr = 2e-4),
    metrics = c("accuracy")
  )
  
  return(model)
}


#' Title
#'
#' @param input_shape 
#' @param num_classes 
#'
#' @source Based on the work on the keras vigniette found at https://github.com/rstudio/keras/blob/master/vignettes/examples/unet.R
#'
#' @return
#' @export
#'
#' @examples
build_unet_model <- function(input_shape = c(128, 128, 1), num_classes = 2){
  
  #---Input-------------------------------------------------------------------------------------
  inputs <- layer_input(name = "input_1", shape = input_shape)
  
  
  #---Downsampling------------------------------------------------------------------------------
  down1 <- inputs %>%
        layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") %>%
        layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") 
    down1_pool <- down1 %>%
        layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))
    
    
   down2 <- down1_pool %>%
        layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") %>%
        layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") 
    down2_pool <- down2 %>%
        layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))
    
    
    down3 <- down2_pool %>%
        layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") %>%
        layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") 
    down3_pool <- down3 %>%
        layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))

    
    down4 <- down3_pool %>%
        layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") %>%
        layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") 
    down4_pool <- down4 %>%
        layer_max_pooling_2d(pool_size = c(2, 2), strides = c(2, 2))
    
  #---Center-----------------------------------------------------------------------------------
    center <- down4_pool %>%
        layer_conv_2d(filters = 1024, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") %>%
        layer_conv_2d(filters = 1024, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") 
  
  #---Upsampling--------------------------------------------------------------------------------
   up4 <- center %>%
        layer_upsampling_2d(size = c(2, 2)) %>%
        {layer_concatenate(inputs = list(down4, .), axis = 3)} %>%
        layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") %>%
        layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") %>%
        layer_conv_2d(filters = 512, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu")
    
    up3 <- up4 %>%
        layer_upsampling_2d(size = c(2, 2)) %>%
        {layer_concatenate(inputs = list(down3, .), axis = 3)} %>%
        layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") %>%
        layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") %>%
        layer_conv_2d(filters = 256, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu")
    
    up2 <- up3 %>%
        layer_upsampling_2d(size = c(2, 2)) %>%
        {layer_concatenate(inputs = list(down2, .), axis = 3)} %>%
        layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") %>%
        layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") %>%
        layer_conv_2d(filters = 128, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu")
    
    up1 <- up2 %>%
        layer_upsampling_2d(size = c(2, 2)) %>%
        {layer_concatenate(inputs = list(down1, .), axis = 3)} %>%
        layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") %>%
        layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu") %>%
        layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = "same") %>%
        layer_batch_normalization() %>%
        layer_activation("relu")
  
 #---Classification/Output---------------------------------------------------------------------
  classify <- layer_conv_2d(up1, filters = num_classes, kernel_size = c(1, 1), activation = "sigmoid")
  
  
  # Build specified model and assign it to variable
  model <- keras_model(
    inputs = inputs,
    outputs = classify
  )
  
  # Compile model
  model %>% compile(
    loss = "binary_crossentropy",
    optimizer = optimizer_sgd(lr = 2e-4),
    metrics = c("accuracy")
  )
  
  
  return(model)
}
  

#' Threshold predicition probabilities to make class predictions
#'
#' @param threshold Value used as threshold to determine class. Value needs to be between 0.0 and 1.0. Reflects needed class probability for a pixel to be considered either class.
#' @param predictions Array of class predictions values returned from Keras' model based prediction function.
#'
#' @return 2D array of binary values (0 or 1) for each pixel in the prediciton tiles.
#' @export
#'
#' @examples \dontrun{class_array <- binary_threshold_results(prediciton_array, 0.95)} This thresholds an array of predicitons with a minimum probability of 95% for class to. This can be interpreted as, for example, "A pixel needs to have at least a 95% probability of beeing a tree to be considered as one for the final result".
threshold_results <- function(predictions, threshold){
  
  # initiate array to fill with thresholded class values
  results <- array(dim = c(dim(predictions)[1], dim(predictions)[2], dim(predictions)[3]))
  
  # for each tile in predicitions
  for (i in 1:dim(predictions)[1]) {
    
    # for each x coordinate
    for (j in 1:dim(predictions)[2]){
      
      # for each y coordiante
      for (k in 1:dim(predictions)[3]) {
        
        # for each class in prediction
        for(l in 1:dim(predictions)[4]) {
          
          # if class 2 is less probable than given threshold
          if (predictions[i, j, k, 1] <= threshold){
            
            # set class in result array to 0
            results[i, j, k] = 0
          }
          
          # if threshold is exceeded
          else {
            
            # set class in result array to 1
            results[i, j, k] = 1
          }
        }
      }
    }
  }
  
  return(results)
}


#' Build a prediciton map for the complete test area
#'
#' @param prediction_tiles (thresholded) Output of a prediciton made using the Keras model
#' @param columns Number of columns/tiles on x-axis. Used to break rows of input tiles
#'
#' @return 2D array of predicted class values 
#' @export
#'
#' @examples \dontrun{result_map <- build_map(test_data[ , , ], 17)}
superset_results <- function(prediction_tiles, columns){
  
  # determine tile resolution of map from input 
  x_resolution <- dim(prediction_tiles)[2]
  y_resolution <- dim(prediction_tiles)[3]
  
  # calculate number of rows given number of tiles and columns
  rows <- (dim(prediction_tiles)[1] / columns)
  
  # initiate array with dimensions of test area to fill with prediciton data
  map_array <- array(dim = c((rows * x_resolution), (columns * y_resolution)))
  
  # initiate counters for looping
  col_count <- 0
  row_count <- 0
  row_mod <- 0
  
  
  # for each prediciton tile
  for (i in 1:dim(prediction_tiles)[1]){

    # for each x
    for (j in 1:dim(prediction_tiles)[2]){
      # determine current x coordinate
      x_coor <- j + (col_count * x_resolution)
      
      # for each y
      for (k in 1:dim(prediction_tiles)[3]){
        # determine current y coordinate
        y_coor <- k + (row_count * y_resolution)
        
        # insert predicted value 
        map_array[x_coor, y_coor] <- prediction_tiles[i, j, k]
      }
    }
    
    # increase row_count after each loop
    row_count <- (row_count + 1)
    
    # if the maximum number of tiles per row is reached
    if (row_count == columns){
      # reset position in row count
      row_count <- 0
      
      # increase column count 
      col_count <- (col_count + 1)
    }
  }
  
  return(map_array)
}
```

```{r data_generation}

train_balance <- sum(data[[2]] != 0) / length(data[[2]])
test_balance <- sum(data[[4]] != 0) / length(data[[4]])

# Build tensors 
tf_train_tiles <- k_constant(data[[1]][ , , , 1:3])
tf_train_masks <- k_constant(to_categorical(data[[2]], num_classes = 2))

tf_test_tiles <- k_constant(data[[3]][ , , , 1:3])
tf_test_masks <- k_constant(to_categorical(data[[4]], num_classes = 2))


tf_target_tiles <- k_constant(data[[5]][ , , , 1:3])
```

```{r}

model <- build_unet_model(input_shape = c(128, 128, 3), num_classes = 2)


image_datagen <- image_data_generator(
  rotation_range = 180,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  horizontal_flip = TRUE,
  vertical_flip = TRUE,
  validation_split = 0.2
)

history <- model %>% 
  fit_generator(
    epochs = 250,
    steps_per_epoch = dim(data[[1]])[1] / 32,
    
    generator = flow_images_from_data(
      tf_train_tiles, 
      tf_train_masks,
      image_datagen,
      subset = "training"),
    
    validation_data = flow_images_from_data(
      tf_train_tiles, 
      tf_train_masks,
      image_datagen,
      subset = "validation")
  )


model %>% evaluate(tf_test_tiles, tf_test_masks)

predictions <- model %>% predict(tf_target_tiles)

results <- threshold_results(predictions, 0.85)

map <- superset_results(results, 10)
test <- superset_results(data[[5]][, , , 1], 10)


par(mfrow=c(1,2))
image(raster(test), main = "Input: RGB, R shown")
image(raster(map), main = "Predicted Classes")
```

```{r metric}

# create metric using backend tensor functions
metric_mean_pred <- custom_metric("mean_pred", function(y_true, y_pred) {
  k_mean(y_pred)
})

```

model %>% save_model_hdf5("/home/basti/Documents/latest_model.h5")
```

Notes:   
  # SGD, 4, 250 epochs, 15 steps, loss 0,18, acc 94.5
  # SGD, 5, ", ", loss 0.39, vaL_loss 0.42, acc 93.5 --> LR too low
  
  # ADAM 4 too fast
  # ADAM, 5, 250 epochs, 15 step, loss 0.188, val_loss 0.38, acc 94.5 --> overfit, result not good
  
  # ADAGRAD, 250, 15, l 0.15, vl 0.29, acc 94.5

