---
author: "Sebastian Holtkamp"
date: "05.02.2020"
title: "Master_Thesis"
output: html_document
---
  
```{r setup, include = FALSE}
library(keras)
library(abind)
library(raster)
library(deepdrone)
library(RColorBrewer)


# Make Keras backend accessable
K <- backend()

# define colors for plotting
cols <- brewer.pal(7, "RdYlGn")
cols2 <- rev(brewer.pal(5, "RdYlGn"))

# define channels used 
channels <- c(1, 2, 3) # --> Blue Green Red


# ----- Prepare Data ------------------------------------------------------------------------------------------
# load tile data
# data <- load_data()

# add NDVI to data 
# data[[1]] <- add_ndvi(data[[1]], 3, 4) # add NDVI to training data
# data[[3]] <- add_ndvi(data[[3]], 3, 4) # add NDVI to predicition test area

# balance dataset if desired
# pixel_balanced_data <- balance_data("pixel", data, 0.5)
# image_balanced_data <- balance_data("image", data, 0.5)

# Build tensors of data
load("C:/Users/Basti/Desktop/split_data.RData")
train_tensors <- tensorize_data(data, channels, c(1, 316, 328, 581, 617, 632))
test_tensor <- tensorize_data(data, channels, c(1, 81))

# organize tensors as lists
train_tile_tensors <- train_tensors[[1]]
train_mask_tensors <- train_tensors[[2]]
test_tile_tensor <- test_tensor[[1]]
test_mask_tensor <- test_tensor[[2]]

full_train_tile_tensor <- k_concatenate(c(train_tile_tensors[[1]],
                                          train_tile_tensors[[2]],
                                          train_tile_tensors[[3]],
                                          train_tile_tensors[[4]],
                                          train_tile_tensors[[5]]),
                                          1)

full_train_mask_tensor <- k_concatenate(c(train_mask_tensors[[1]],
                                          train_mask_tensors[[2]],
                                          train_mask_tensors[[3]],
                                          train_mask_tensors[[4]],
                                          train_mask_tensors[[5]]),
                                          1)

rm(train_tensors, test_tensor)

# To view data use e.g.:
# image(raster(data[[1]][1,,,1]))

# ----- Prepare Dice ------------------------------------------------------------------------------------------
#Based on the implementation showcased at https://blogs.rstudio.com/tensorflow/posts/2019-08-23-unet/

#define dice metric
dice <- keras::custom_metric("dice", function(y_true, y_pred, smooth = 1.0) {
  
  # flatten ground truth and prediction tensors into 1D tensors
  y_true_f <- k_flatten(y_true)
  y_pred_f <- k_flatten(y_pred)
  
  intersection <- k_sum(y_true_f * y_pred_f)
  
  # calculate Dice coefficient
  (2 * intersection + smooth) / (k_sum(y_true_f) + k_sum(y_pred_f) + smooth)
})

# define dice loss
bce_dice_loss <- function(y_true, y_pred) {
  
  # calculate loss
  result <- loss_binary_crossentropy(y_true, y_pred) + (1 - dice(y_true, y_pred))
  
  return(result)
}



#----- Prepare Training Components ----------------------------------------------------------------------------

# define image data generator
image_datagen <- image_data_generator(
  rotation_range = 20,
  zoom_range = 0.2,
  horizontal_flip = TRUE,
  vertical_flip = TRUE,
  validation_split = 0.2
)

# define parameters for early stopping
early_stopping_call = callback_early_stopping(
                        monitor = "val_dice",
                        mode = "max",
                        min_delta = 0.0001,
                        patience = 15,
                        restore_best_weights = TRUE
                        )
```

```{r model, include = FALSE}

model <- build_unet_original()

```

```{r train_models_spatial_loocv}

# initiate lists to hold results for crossvalidated training
histories <- list()
evaluations <- list()


# train a model for each area in data, leaving it out of training and using it for validation
for(i in 1:5){
  
  cross_validation_tensor_selection <- loocv(train_tile_tensors, train_mask_tensors, i)
  these.tiles <- cross_validation_tensor_selection[1]
  these.masks <- cross_validation_tensor_selection[2]
  
  this.model <- clone_model(model)
  
  this.model %>% compile(
                  loss = "binary_crossentropy",
                  optimizer = optimizer_sgd(lr = 0.0001, momentum = 0.99),
                  metrics = list(dice, "accuracy")
                  )
  
  # fit cloned model to selected training data
  this.history <- this.model %>%
    fit_generator(
      epochs = 10,
      steps_per_epoch = dim(these.tiles[[1]])[1] / 16,

      generator = flow_images_from_data(
        batch_size = 16,
        these.tiles[[1]],
        these.masks[[1]],
        image_datagen
        #subset = "training"
        ),

      validation_data = flow_images_from_data(
        batch_size = 16,
        train_tile_tensors[[i]],
        train_mask_tensors[[i]],
        image_datagen
        #subset = "validation"
        ),
      
      callbacks = early_stopping_call
    )
  
  # evaluate trained model
  this.evaluation = evaluate(this.model, test_tile_tensor[[1]], test_mask_tensor[[1]])

  # save history and evaluation of this iteration
  histories[[paste0("area_", i)]] <- this.history
  evaluations[[paste0("area_", i)]] <- this.evaluation

  K$clear_session()
}

# select best and worst model depending on dice
selected_models <- select_models(models, evaluations)

best_model <- clone_model(selected_models[[1]])
best_model %>% compile(
                  loss = "binary_crossentropy",
                  optimizer = optimizer_sgd(lr = 0.0001, momentum = 0.99),
                  metrics = list(dice, "accuracy")
                  )


loocv_eval <- evaluate_loocv(evaluations)

```

patial_cross_val_history <- this.model %>%
                                  fit_generator(
                                  epochs = 250,
                                  steps_per_epoch = dim(data[[1]])[1] / 16,
    
                                  generator = flow_images_from_data(
                                    batch_size = 16,
                                    full_train_tile_tensor,
                                    full_train_mask_tensor,
                                    image_datagen,
                                    subset = "training"
                                    ),
                            
                                  validation_data = flow_images_from_data(
                                    batch_size = 16,
                                    full_train_tile_tensor,
                                    full_train_mask_tensor,
                                    image_datagen,
                                    subset = "validation"
                                    ),
                                  
                                  callbacks = early_stopping_call
                                  )




```{r predict}

# select best and worst model depending on dice
selected_models <- select_models(models, evaluations)

# use both models to predict classes of target area
best_pred <- selected_models[[1]] %>% predict(data[[3]][ , , , channels])
worst_pred <- selected_models[[2]] %>% predict(data[[3]][ , , , channels])

# combine tiles of class 1 and 2 predicted by best model into maps
best_map_c1 <- superset_results(best_pred[ , , , 1], 8)
best_map_c2 <- superset_results(best_pred[ , , , 2], 8)

# combine tiles of class 1 and 2 predicted by worst model into maps
worst_map_c1 <- superset_results(worst_pred[ , , , 1], 8)
worst_map_c2<- superset_results(worst_pred[ , , , 2], 8)

# try binary classifaction on best model predictions
binary_map <- filter_results_binary(best_map_c1, best_map_c2)

# try thresholding on best model predictions and combine tiles
thresholded_best_pred<- threshold_results(best_pred, 0.788)
thresholded_best_map <- superset_results(thresholded_best_pred, 8)

thresholded_worst_pred<- threshold_results(worst_pred, 0.8672)
thresholded_worst_map <- superset_results(thresholded_worst_pred, 8)

# add coordinated and projections to maps
best_map_raster <- raster_maps(data = data, map = best_map_c1)
worst_map_raster <- raster_maps(data = data, map = worst_map_c1)
binary_map_raster <- raster_maps(data = data, map = binary_map)
thresholded_best_map_raster <- raster_maps(data = data, map = thresholded_best_map)
thresholded_worst_map_raster <- raster_maps(data = data, map = thresholded_worst_map)

# calculate differences between best and worst results
difference_map <- abs(best_map_raster - worst_map_raster)



plot(best_map_raster, main = "Predicted Classes for Target Area, Highest Dice", xlab = "Longitude [°E]", ylab = "Lattitude [°N]", col = cols)
plot(worst_map_raster, main = "Predicted Classes for Target Area, Lowest Dice", xlab = "Longitude [°E]", ylab = "Lattitude [°N]", col = cols)
plot(binary_map_raster, main = "Predicted Binary Classes for Target Area", xlab = "Longitude [°E]", ylab = "Lattitude [°N]")
plot(thresholded_best_map_raster, main = "Predicted Thresholded Classes for Target Area", xlab = "Longitude [°E]", ylab = "Lattitude [°N]", col = c("white", "darkgreen"), legend = FALSE)
plot(thresholded_worst_map_raster, main = "Predicted Thresholded Classes for Target Area", xlab = "Longitude [°E]", ylab = "Lattitude [°N]", col = c("white", "darkgreen"), legend = FALSE)

plot(difference_map, main = "Differences in Predicted Classes for Target Area", xlab = "Longitude [°E]", ylab = "Lattitude [°N]", col = cols2)

```
```{r}
png("C:/Users/Basti/Desktop/binary.png", width=1920, height=1080, pointsize = 20)
plot(binary_map_raster, main = "Predicted Classes for Target Area", xlab = "Longitude [°E]", ylab = "Lattitude [°N]", col = cols, legend = FALSE)
dev.off()

png("C:/Users/Basti/Desktop/best.png", width=1920, height=1080, pointsize = 20)
plot(best_map_raster, main = "Predicted Classes for Target Area", xlab = "Longitude [°E]", ylab = "Lattitude [°N]", col = cols)
dev.off()

png("C:/Users/Basti/Desktop/worst.png", width=1920, height=1080, pointsize = 20)
plot(worst_map_raster, main = "Predicted Classes for Target Area", xlab = "Longitude [°E]", ylab = "Lattitude [°N]", col = cols)
dev.off()

png("C:/Users/Basti/Desktop/diff.png", width=1920, height=1080, pointsize = 20)
plot(difference_map, main = "Difference in Predicted Classes for Target Area", xlab = "Longitude [°E]", ylab = "Lattitude [°N]", col = cols2)
dev.off()

png("C:/Users/Basti/Desktop/tres_b.png", width=1920, height=1080, pointsize = 20)
plot(thresholded_best_map_raster, main = "Predicted Binary Classes for Target Area", xlab = "Longitude [°E]", ylab = "Lattitude [°N]", col = c("white", "darkgreen"), legend = FALSE)
dev.off()

png("C:/Users/Basti/Desktop/tres_w.png", width=1920, height=1080, pointsize = 20)
plot(thresholded_worst_map_raster, main = "Predicted Binary Classes for Target Area", xlab = "Longitude [°E]", ylab = "Lattitude [°N]", col = c("white", "darkgreen"), legend = FALSE)
dev.off()
```

writeRaster(elev.r, "elev_out.tif", format="GTiff" )

all.equal(get_weights(models$area_1), get_weights(models$area_2))


prime <- models[[1]]
predictions <- prime %>% predict(target[ , , 1:3])

results <- threshold_results(predictions, 0.57)
map <- superset_results(results, 10)
image(raster(map), main = "Predicted Classes")


test <- superset_results(data[[5]][, , , 7], 10)


par(mfrow=c(1,2))
image(raster(test), main = "Input: NIR, RE, NDVI, NDVI shown")
image(raster(map), main = "Predicted Classes")
```

model %>% save_model_hdf5("F:/Master_Thesis/model_custom.h5")
```

Notes:   
  # SGD, 4, 250 epochs, 15 steps, loss 0,18, acc 94.5
  # SGD, 5, ", ", loss 0.39, vaL_loss 0.42, acc 93.5 --> LR too low
  
  # ADAM 4 too fast
  # ADAM, 5, 250 epochs, 15 step, loss 0.188, val_loss 0.38, acc 94.5 --> overfit, result not good
  
  # ADAGRAD, 250, 15, l 0.15, vl 0.29, acc 94.5


# invert msak:

#data[[2]] <- +(!data[[2]])
#data[[4]] <- +(!data[[4]])

oom errors
#grid.raster(map)
